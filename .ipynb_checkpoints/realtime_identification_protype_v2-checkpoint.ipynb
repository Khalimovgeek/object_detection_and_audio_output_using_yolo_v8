{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "004f325d-e870-4f70-90cc-2328ecf0e6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize YOLOv8 model\n",
    "model = YOLO('yolov8m_saved_model/yolov8m_float32.tflite')\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                  \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                  \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "                  \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "                  \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "                  \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "                  \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "                  \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "                  \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "                  \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "                  ]\n",
    "# Initialize pyttsx3 engine\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "90b23a32-b426-46de-bb1c-115b3906eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio(path):\n",
    "    \n",
    "    language = 'en'\n",
    "    results = model(path)\n",
    "    x = \"There \"  # Initialize x\n",
    "    for result in results:\n",
    "        boxes =result.boxes.cls\n",
    "        boxes_int = [int(x) for x in boxes]\n",
    "        counter = Counter(boxes_int)\n",
    "\n",
    "        print(counter)  # Check what boxes contains\n",
    "        for i, (box, count) in enumerate(counter.items()):\n",
    "            if i != len(counter) - 1 and i != 0:\n",
    "                if count == 1:\n",
    "                    x += f\"a {classNames[int(box)]} , \"\n",
    "                else:\n",
    "                    x += f\"{count} {classNames[int(box)]}s , \"\n",
    "            elif i == 0:\n",
    "                if count == 1:\n",
    "                    x += f\"is a {classNames[int(box)]} , \"\n",
    "                else:\n",
    "                    x += f\"are {count} {classNames[int(box)]}s , \"\n",
    "            else:\n",
    "                if count == 1:\n",
    "                    x += f\"and a {classNames[int(box)]} \"\n",
    "                else:\n",
    "                    x += f\"and {count} {classNames[int(box)]}s \"\n",
    "    \n",
    "    x+= \"in front of you.\"\n",
    "    print(x)\n",
    "    pyttsx3.speak(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "67027dfc-2b13-49f7-9266-92664f9be616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects_and_speak(frame):\n",
    "    # Convert frame to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Run YOLOv8 tracking\n",
    "    results = model.track(frame, persist=True)\n",
    "    boxes = results[0].boxes.xywh.cpu()\n",
    "    #probs = results.probs.cpu()\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        print(\"No moving objects detected.\")\n",
    "    else:\n",
    "        objects_with_direction = []  # List to store objects along with their direction\n",
    "        objects=[]\n",
    "        for j,box in enumerate(boxes):\n",
    "            # Extract box coordinates\n",
    "            x, y, w, h = box\n",
    "            # Calculate box center\n",
    "            center_x =[]\n",
    "            center_x.append(x)\n",
    "            for xx in center_x:\n",
    "            \n",
    "                print(xx)\n",
    "                # Determine direction based on box center\n",
    "                if xx <= 400:\n",
    "                    direction = \"left\"\n",
    "                elif xx >= 900:\n",
    "                    direction = \"right\"\n",
    "                else:\n",
    "                    direction = \"middle\"\n",
    "                print(direction)\n",
    "                object_name = classNames[int(results[0].boxes.cls[j])]\n",
    "                print(object_name)\n",
    "                objects_with_direction.append(f\" {direction}\")\n",
    "                objects.append(f\" {object_name}\")\n",
    "        text_to_speak = \", \".join(objects_with_direction) \n",
    "        text_to_speak += \",\".join(objects)\n",
    "        engine.say(text_to_speak)\n",
    "        engine.runAndWait()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "445b8ed0-87b3-45fc-88bd-7aceb5004e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 person, 1139.3ms\n",
      "Speed: 6.0ms preprocess, 1139.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "tensor(1042.5081)\n",
      "right\n",
      "person\n",
      "\n",
      "0: 640x640 1 person, 1148.1ms\n",
      "Speed: 3.0ms preprocess, 1148.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "tensor(914.5387)\n",
      "right\n",
      "person\n",
      "\n",
      "0: 640x640 1 person, 1156.6ms\n",
      "Speed: 6.0ms preprocess, 1156.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "tensor(1182.6370)\n",
      "right\n",
      "person\n",
      "\n",
      "0: 640x640 1 person, 1235.5ms\n",
      "Speed: 4.0ms preprocess, 1235.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "tensor(1028.9409)\n",
      "right\n",
      "person\n",
      "\n",
      "0: 640x640 1 person, 1130.3ms\n",
      "Speed: 3.0ms preprocess, 1130.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "tensor(1084.4281)\n",
      "right\n",
      "person\n",
      "\n",
      "0: 640x640 2 persons, 2 books, 1 teddy bear, 1121.7ms\n",
      "Speed: 16.6ms preprocess, 1121.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "tensor(619.9271)\n",
      "middle\n",
      "person\n",
      "tensor(1414.1353)\n",
      "right\n",
      "person\n",
      "tensor(694.7793)\n",
      "middle\n",
      "teddy bear\n",
      "tensor(316.5843)\n",
      "left\n",
      "book\n",
      "tensor(441.3177)\n",
      "middle\n",
      "book\n",
      "\n",
      "0: 640x640 2 persons, 1161.6ms\n",
      "Speed: 5.3ms preprocess, 1161.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "tensor(718.9000)\n",
      "middle\n",
      "person\n",
      "tensor(1496.1262)\n",
      "right\n",
      "person\n"
     ]
    }
   ],
   "source": [
    "# Main function to capture frames and handle events\n",
    "def detect():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 1920)\n",
    "    cap.set(4, 1080)\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        cv2.imshow('Webcam', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        \n",
    "        # Perform object detection and speak the detected objects and their directions when 'u' is pressed\n",
    "        if key == ord('u'):\n",
    "            detect_objects_and_speak(frame)  # Call the audio function with the path to the temporary image\n",
    "        elif key == ord('r'):\n",
    "            cv2.imwrite(\"temp_img.jpg\", frame)  # Save a temporary image\n",
    "            audio(\"temp_img.jpg\")  # Call the audio function with the path to the temporary image\n",
    "        # Break the loop if 'q' is pressed\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the detect function\n",
    "detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e4664-2444-4089-8294-1e995a9c93fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6295b749-cb2a-462d-b51b-25edeef4571f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a601f6-298a-4f98-95de-c45028ad9955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
